Вот скорректированное описание с учётом изменений и структуры классов:

# Ollama Python Chat

Этот проект демонстрирует использование модели `Llama` от Ollama в Python, предоставляя инструменты для выполнения запросов, генерации текста и ведения интерактивного чата с моделью.

## Описание проекта

Проект включает два основных класса:
1. **`BaseModelRunner`** — предоставляет базовые функции для работы с моделью, такие как генерация текста.
2. **`ChatModelRunner`** — наследует функциональность `BaseModelRunner`, добавляя возможность ведения чата с сохранением истории сообщений.

### Основные функции:
- Инициализация и запуск модели Llama.
- Генерация текста на основе заданных промптов (без интерактивного чата).
- Ведение диалога с моделью в режиме чата с сохранением контекста переписки.

## Установка Ollama

Для работы с моделью `Llama`, необходимо установить Ollama. Инструкция по установке доступна на [официальном сайте Ollama](https://www.ollama.com):

1. Перейдите на страницу [скачивания Ollama](https://www.ollama.com/download) и следуйте инструкциям для вашей операционной системы.
   
2. После установки Ollama, вы можете загружать модели командой:

   ```bash
   ollama pull llama3.1
   ```

   Это команда по умолчанию установит модель в стандартную директорию Ollama.

### Рекомендации по оборудованию

Для корректной работы модели рекомендуется использовать видеокарту с объёмом памяти не менее 8 ГБ. Модели могут потребовать значительные ресурсы для обработки сложных запросов.

## Установка проекта

1. Клонируйте репозиторий на локальный компьютер:
   ```bash
   git clone https://github.com/AntonSHBK/ollama_python_chat
   cd ollama_python_chat
   ```

2. Создайте виртуальное окружение и активируйте его:
   ```bash
   python -m venv .venv
   # Для Windows
   .\.venv\Scripts\activate
   # Для Linux/MacOS
   source .venv/bin/activate
   ```

3. Установите зависимости:
   ```bash
   pip install -r requirements.txt
   ```

4. Убедитесь, что у вас установлен `ollama` и модель Llama, которую вы хотите использовать. Если модель еще не установлена, запустите:
   ```bash
   python install_model.py
   ```

## Настройка

Перед запуском проекта создайте файл `.env` в корне проекта и укажите имя модели и путь для моделей (при необходимости):

```env
MODEL_NAME=llama3.1
OLLAMA_MODELS=D:\
```

## Запуск и тестирование

Для запуска и тестирования функционала используйте скрипт `model.py` или `jupyter notebook` - `chating_with_model.ipynb`:

```bash
python model.py
```

### Пример использования

1. **`BaseModelRunner`**:
   - Используется для генерации текста на основе заданного запроса. Пример:
     ```python
     runner = BaseModelRunner()
     response = runner.generate("Расскажи мне о модели Llama.")
     print(response)
     ```

2. **`ChatModelRunner`**:
   - Позволяет вести чат с моделью, сохраняя контекст переписки. Пример:
     ```python
     runner = ChatModelRunner()
     response = runner.send_message("Привет! Как тебя зовут?")
     print(response)
     ```

## О модели Llama

Llama — это мощная языковая модель, разработанная для выполнения различных задач обработки естественного языка. Она может использоваться для создания чат-ботов, генерации текста, перевода и других задач, связанных с обработкой текста. Модель отличается высокой точностью и способностью понимать контекст, что делает её эффективным инструментом для работы с естественным языком.

### Официальные источники

- [Официальный сайт Ollama](https://www.ollama.com)
- [Документация по Llama](https://www.ollama.com/llama)

## Лицензия

Этот проект распространяется под лицензией Apache-2.0 license. Подробности смотрите в файле `LICENSE`.
